{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc76b64",
   "metadata": {},
   "source": [
    "##### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd60757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from textwrap import wrap\n",
    "import spacy\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller,acf,pacf\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e8319",
   "metadata": {},
   "source": [
    "# reviews\n",
    "\n",
    "## digital_music_5:\n",
    "\n",
    "##### importing data into dataframe fortmat from zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g=gzip.open(path,'rb')\n",
    "    for i in g:\n",
    "        yield eval(i)\n",
    "\n",
    "def getDF(path):\n",
    "    x=0\n",
    "    df1={}\n",
    "    for j in parse(path):\n",
    "        df1[x]=j\n",
    "        x=x+1\n",
    "    return pd.DataFrame.from_dict(df1,orient='index')\n",
    "df1 = getDF('reviews_Digital_Music_5.json.gz')\n",
    "\n",
    "# checking no. of rows and columns in the dataframe\n",
    "print(df1.shape)\n",
    "\n",
    "# top 3 records\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of non-numeric variables\n",
    "\n",
    "# Number of unique customers\n",
    "print('\\nNumber of unique customers : {}'.format(len(df1['reviewerID'].unique())))\n",
    "      \n",
    "# Number of unique products\n",
    "print('\\nNumber of unique products : {}'.format(len(df1['asin'].unique())))\n",
    "      \n",
    "# Review number per unique customer\n",
    "print('\\nReview per customer: {}'.format((len(df1)/len(df1['reviewerID'].unique()))))      \n",
    "\n",
    "# Review number per unique product \n",
    "print('\\nReview per product: {}'.format((len(df1)/len(df1['asin'].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f37db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply() method to combine two columns of text\n",
    "df1[\"review\"] = df1[[\"reviewText\", \"summary\"]].apply(\" \".join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d0a34",
   "metadata": {},
   "source": [
    "##### deriving helpful ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83176287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the helpful column into help numerator and help denominator\n",
    "df1['help_num'] = df1['helpful'].str.get(0)\n",
    "df1['help_den'] = df1['helpful'].str.get(1)\n",
    "\n",
    "# calculating the helpful ratio of the reviews\n",
    "df1['help_ratio'] = df1['help_num'].div(df1['help_den'])\n",
    "df1['help_ratio'] = df1['help_ratio'].replace(np.nan, 0)\n",
    "\n",
    "# creating bins for help ratio\n",
    "bins = [0.0, 0.25, 0.50, 0.75, 1.0]\n",
    "slot = ['not_helpful',\n",
    "        'less_helpful',\n",
    "        'more_helpful',\n",
    "        'most_helpful']\n",
    "df1['help_slot'] = pd.cut(df1['help_ratio'],bins,labels=slot)\n",
    "df1['help_slot'] = df1['help_slot'].replace(np.nan, 'not_helpful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40514f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 products with highest no of ratings\n",
    "h1 = df1['asin'].value_counts().head(10)\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebca4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "help_df1 = df1[(df1.asin == 'B0007NFL18')|(df1.asin == 'B000084T18')|(df1.asin == 'B00006690F')|(df1.asin == 'B00004T9UF')\n",
    "              |(df1.asin == 'B00005YW4H')|(df1.asin == 'B0006ZQ9BS')|(df1.asin == 'B0000AGWFX')|(df1.asin == 'B00005O54Q')\n",
    "             |(df1.asin == 'B00000163G')|(df1.asin == 'B00065XJ52')]\n",
    "help_rate1 = pd.crosstab(help_df1.asin, help_df1.help_slot, rownames = ['asin'], colnames = ['help_slot'])\n",
    "help_rate1.plot(kind = 'bar', figsize= (15, 3))\n",
    "plt.ylabel('frequency of rating')\n",
    "plt.title ('help analysis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45b03d",
   "metadata": {},
   "source": [
    "##### converting review time from object to date and time and extracting YEAR from the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41afd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['reviewTime'] = pd.to_datetime(df1['reviewTime'])\n",
    "df1['year'] = pd.DatetimeIndex(df1['reviewTime']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f6fab",
   "metadata": {},
   "source": [
    "## musical_instruments_5: reviews\n",
    "\n",
    "##### importing data into dataframe fortmat from zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g=gzip.open(path,'rb')\n",
    "    for i in g:\n",
    "        yield eval(i)\n",
    "\n",
    "def getDF(path):\n",
    "    x=0\n",
    "    df2={}\n",
    "    for j in parse(path):\n",
    "        df2[x]=j\n",
    "        x=x+1\n",
    "    return pd.DataFrame.from_dict(df2,orient='index')\n",
    "df2 = getDF('reviews_Musical_Instruments_5.json.gz')\n",
    "\n",
    "# checking no. of rows and columns in the dataframe\n",
    "print(df2.shape)\n",
    "\n",
    "# top 3 records\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e92281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of non-numeric variables\n",
    "\n",
    "# Number of unique customers\n",
    "print('\\nNumber of unique customers : {}'.format(len(df2['reviewerID'].unique())))\n",
    "      \n",
    "# Number of unique products\n",
    "print('\\nNumber of unique products : {}'.format(len(df2['asin'].unique())))\n",
    "      \n",
    "# Review number per unique customer\n",
    "print('\\nReview per customer: {}'.format((len(df2)/len(df2['reviewerID'].unique()))))      \n",
    "\n",
    "# Review number per unique product \n",
    "print('\\nReview per product: {}'.format((len(df2)/len(df2['asin'].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply() method to combine two columns of text\n",
    "df2[\"review\"] = df2[[\"reviewText\", \"summary\"]].apply(\" \".join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998675ec",
   "metadata": {},
   "source": [
    "##### deriving helpful ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the helpful column into help numerator and help denominator\n",
    "df2['help_num'] = df2['helpful'].str.get(0)\n",
    "df2['help_den'] = df2['helpful'].str.get(1)\n",
    "\n",
    "# calculating the helpful ratio of the reviews\n",
    "df2['help_ratio'] = df2['help_num'].div(df2['help_den'])\n",
    "df2['help_ratio'] = df2['help_ratio'].replace(np.nan, 0)\n",
    "\n",
    "# creating slots for help ratio\n",
    "bins = [0.0, 0.25, 0.50, 0.75, 1.0]\n",
    "slot = ['not_helpful',\n",
    "        'less_helpful',\n",
    "        'more_helpful',\n",
    "        'most_helpful']\n",
    "\n",
    "df2['help_slot'] = pd.cut(df2['help_ratio'],bins,labels=slot)\n",
    "df2['help_slot'] = df2['help_slot'].replace(np.nan, 'not_helpful')\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = df2['asin'].value_counts().head(10)\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afda019",
   "metadata": {},
   "outputs": [],
   "source": [
    "help_df2 = df2[(df2.asin == 'B003VWJ2K8')|(df2.asin == 'B0002E1G5C')|(df2.asin == 'B0002F7K7Y')|(df2.asin == 'B003VWKPHC')\n",
    "              |(df2.asin == 'B0002H0A3S')|(df2.asin == 'B0002CZVXM')|(df2.asin == 'B0006NDF8A')|(df2.asin == 'B0009G1E0K')\n",
    "             |(df2.asin == 'B0002E2KPC')|(df2.asin == 'B0002GLDQM')]\n",
    "\n",
    "help_rate2 = pd.crosstab(help_df2.asin, help_df2.help_slot, rownames = ['asin'], colnames = ['help_slot'])\n",
    "help_rate2.plot(kind = 'bar', figsize= (15, 3))\n",
    "plt.ylabel('frequency of rate')\n",
    "plt.title ('help analysis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ac8b2",
   "metadata": {},
   "source": [
    "##### converting review time from object to date and time and extracting YEAR from the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['reviewTime'] = pd.to_datetime(df2['reviewTime'])\n",
    "df2['year'] = pd.DatetimeIndex(df2['reviewTime']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e983f6",
   "metadata": {},
   "source": [
    "##### plot showing Count of Reviews under each Ratings for both data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# digital music: count of ratings in respect to each review\n",
    "rate1 = df1['overall'].value_counts()\n",
    "print(\"digital music: count of ratings in respect to each review: \")\n",
    "print(rate1)\n",
    "plt.subplot(1, 2, 1) # row 1, col 2 index 1\n",
    "rate1.plot(kind = 'bar', figsize= (10, 5))\n",
    "plt.xlabel('no of reviews')\n",
    "plt.title ('Digital Music: Ratings');\n",
    "\n",
    "# musical instruments: count of ratings inrespect to each review\n",
    "rate2 = df2['overall'].value_counts()\n",
    "print(\"musical instrument: count of ratings in respect to each review: \")\n",
    "print(rate2)\n",
    "plt.subplot(1, 2, 2) # row 1, col 2 index 2\n",
    "rate2.plot(kind = 'bar', figsize= (10, 5))\n",
    "plt.xlabel('no of reviews')\n",
    "plt.title ('Musical Instrument: Ratings');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20ef6e",
   "metadata": {},
   "source": [
    "##### punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2de85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First remove Punctuations from the Reviews\n",
    "def punctuation_removal(messy_str):\n",
    "    clean_list = [char for char in messy_str if char not in string.punctuation]\n",
    "    clean_str = ''.join(clean_list)\n",
    "    return clean_str\n",
    "\n",
    "# apply the function\n",
    "df1['review'] = df1['review'].apply(punctuation_removal)\n",
    "df2['review'] = df2['review'].apply(punctuation_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419899c",
   "metadata": {},
   "source": [
    "##### number removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function to remove Numbers from the reviews\n",
    "def number_removal(list_text):\n",
    "    list_text_new = []\n",
    "    for i in list_text:\n",
    "        if not re.search('\\d', i):\n",
    "            list_text_new.append(i)\n",
    "    return ''.join(list_text_new)\n",
    "\n",
    "# apply the function\n",
    "df1['review'] = df1['review'].apply(number_removal)\n",
    "df2['review'] = df2['review'].apply(number_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07abe70",
   "metadata": {},
   "source": [
    "##### accented charecters removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to remove accented characters\n",
    "def accented_char_removal(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "\n",
    "# apply the function\n",
    "df1['review'] = df1.apply(lambda x: accented_char_removal(x['review']), axis = 1)\n",
    "df2['review'] = df2.apply(lambda x: accented_char_removal(x['review']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f704b0",
   "metadata": {},
   "source": [
    "##### special charecters removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to remove special characters\n",
    "def special_character_removal(text):\n",
    "    pat = r'[^a-zA-Z0-9]' \n",
    "    return re.sub(pat, ' ', text)\n",
    " \n",
    "# apply this function\n",
    "df1['review'] = df1.apply(lambda x: special_character_removal(x['review']), axis = 1)\n",
    "df2['review'] = df2.apply(lambda x: special_character_removal(x['review']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad5654",
   "metadata": {},
   "source": [
    "##### Visualizing the Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbadea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = 'english')\n",
    "def top(df):\n",
    "    words = cv.fit_transform(df.review)\n",
    "    sum_words = words.sum(axis=0)\n",
    "\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "    frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
    "\n",
    "    #plt.style.use('fivethirtyeight')\n",
    "    color = plt.cm.ocean(np.linspace(0, 1, 20))\n",
    "    frequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(10, 2), color = color)\n",
    "    plt.title(\"Most Frequently Occuring Words - Top 20\");\n",
    "    \n",
    "\n",
    "top(df1)\n",
    "\n",
    "top(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0906b077",
   "metadata": {},
   "source": [
    "##### Visualizing the Least Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = 'english')\n",
    "def bottom(df):\n",
    "    words = cv.fit_transform(df.review)\n",
    "    sum_words = words.sum(axis=0)\n",
    "\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "    frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
    "\n",
    "    #plt.style.use('fivethirtyeight')\n",
    "    color = plt.cm.ocean(np.linspace(0, 1, 20))\n",
    "    frequency.tail(20).plot(x='word', y='freq', kind='bar', figsize=(10, 2), color = color)\n",
    "    plt.title(\"Least Frequently Occuring Words - Top 20\");\n",
    "    \n",
    "bottom(df1)\n",
    "\n",
    "bottom(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3d80f",
   "metadata": {},
   "source": [
    "##### plot the Wordscloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa450ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = 'english')\n",
    "def cloud(df):\n",
    "    words = cv.fit_transform(df.review)\n",
    "    sum_words = words.sum(axis=0)\n",
    "\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    wordcloud = WordCloud(background_color = 'black', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(\"Vocabulary from Reviews\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17ec71",
   "metadata": {},
   "source": [
    "##### calculating and ploting distribution of overall ratings over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b12bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(df):\n",
    "    year_rate = pd.crosstab(df.year, df.overall, rownames = ['year'], colnames = ['overall'])\n",
    "    #print(year_rate)\n",
    "    year_rate.plot(kind = 'bar', figsize= (15, 3))\n",
    "    plt.ylabel('frequency of rates')\n",
    "    plt.title ('Overall grouping in terms of Year');\n",
    "    \n",
    "rate(df1)\n",
    "\n",
    "rate(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233cfaf",
   "metadata": {},
   "source": [
    "##### sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews_df['review'] = df['review'].astype('str')\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "def sentiments(df):\n",
    "    df['Polarity'] = df['review'].apply(get_polarity)\n",
    "    df['Sentiment_Type']=''\n",
    "    df.loc[df.Polarity>0,'Sentiment_Type']='POSITIVE'\n",
    "    df.loc[df.Polarity==0,'Sentiment_Type']='NEUTRAL'\n",
    "    df.loc[df.Polarity<0,'Sentiment_Type']='NEGATIVE'\n",
    "    #df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments(df1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72686add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[slice(10, 20)]\n",
    "#df1[(df1.Sentiment_Type == 'NEUTRAL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c18d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments(df2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70775927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2.Sentiment_Type == 'NEUTRAL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(df):\n",
    "    sentiment = df['Sentiment_Type'].value_counts()\n",
    "    print(sentiment)\n",
    "\n",
    "    pos = sentiment[0]\n",
    "    neg = sentiment[1]\n",
    "    neu = sentiment[2]\n",
    "\n",
    "    def sentiment_score(ptv, ntv, ntrl):\n",
    "        if (ptv > ntv) and (ptv > ntrl):\n",
    "            print(\"max sentiment are Positive 😊 \")\n",
    "        elif (ntv > ptv) and (ntv > ntrl):\n",
    "            print(\"max sentiment are Negative 😠 \")\n",
    "        else:\n",
    "            print(\"max sentiment are Neutral 😐 \")\n",
    "    sentiment_score(pos, neg, neu)\n",
    "\n",
    "    df.Sentiment_Type.value_counts().plot(kind='bar', ylabel = 'frequency of sentiments', title=\"Sentiment Analysis\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61455ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632697fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating word clouds\n",
    "cv=CountVectorizer(analyzer='word')\n",
    "def review_wordcloud(data,title):\n",
    "    wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(5 ,5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
    "    plt.show()\n",
    "#df_dtm=df_dtm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36045221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 most positive rated products\n",
    "positive_df1 = df1[(df1.Sentiment_Type == 'POSITIVE')]\n",
    "positive1 = positive_df1[('Sentiment_Type')].groupby(positive_df1['asin']).value_counts()\n",
    "pos_sent1 = pd.DataFrame({'count':((positive1.sort_values(ascending = False)).head(10))}).reset_index()\n",
    "pos_sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pos_sent1.asin\n",
    "pos_df1 = pd.merge(df1, g,on='asin')\n",
    "pos_df1 = pos_df1[(pos_df1.Sentiment_Type == 'POSITIVE')]\n",
    "pos_df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9882aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable = ['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "pos_df1['review'] = pos_df1['review'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf13b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped1 = pos_df1[['asin','review']].groupby(by='asin').agg(lambda x:' '.join(x))\n",
    "df_grouped1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb904b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word')\n",
    "data = cv.fit_transform(df_grouped1['review'])\n",
    "df_dtm1 = pd.DataFrame(data.toarray(), columns = cv.get_feature_names())\n",
    "df_dtm1.index = df_grouped1.index\n",
    "df_dtm1 = df_dtm1.transpose()\n",
    "df_dtm1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2831d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting word cloud for each product\n",
    "for index,product in enumerate(df_dtm1.columns):\n",
    "    review_wordcloud(df_dtm1[product].sort_values(ascending=False),product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886006bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list that is to be converted into a column\n",
    "album_name = ['classic_song_album',\n",
    "           'michael_jackson_thriller_song_album',\n",
    "           'dr_dre_rap_beat_classic_song_album',\n",
    "           'eminem_song_album_1',\n",
    "           'jayz_classic_song_album',\n",
    "           'norah_jones_song_album',\n",
    "           'eminem_song_album_2',\n",
    "           'cent_eminem_rap_beat_song_album',\n",
    "           'andre_love_song_album',\n",
    "           'dre_eminem_cent_good_beat_song_album']\n",
    "\n",
    "# Using 'album_name' as the column name and equating it to the list\n",
    "df_grouped1['album_name'] = album_name\n",
    "df_grouped1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e78db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df2 = df2[(df2.Sentiment_Type == 'POSITIVE')]\n",
    "positive2 = positive_df2[('Sentiment_Type')].groupby(positive_df2['asin']).value_counts()\n",
    "pos_sent2 = pd.DataFrame({'count':((positive2.sort_values(ascending = False)).head(10))}).reset_index()\n",
    "pos_sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pos_sent2.asin\n",
    "pos_df2 = pd.merge(df2, h,on='asin')\n",
    "pos_df2 = pos_df2[(pos_df2.Sentiment_Type == 'POSITIVE')]\n",
    "pos_df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable = ['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "pos_df2['review'] = pos_df2['review'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf41615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped2 = pos_df2[['asin','review']].groupby(by='asin').agg(lambda x:' '.join(x))\n",
    "df_grouped2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word')\n",
    "data = cv.fit_transform(df_grouped2['review'])\n",
    "df_dtm2 = pd.DataFrame(data.toarray(), columns = cv.get_feature_names())\n",
    "df_dtm2.index = df_grouped2.index\n",
    "df_dtm2 = df_dtm2.transpose()\n",
    "df_dtm2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86618b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting word cloud for each product\n",
    "for index,product in enumerate(df_dtm2.columns):\n",
    "    review_wordcloud(df_dtm2[product].sort_values(ascending=False),product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list that is to be converted into a column\n",
    "album_name = ['guitar_strap_lock_screw',\n",
    "           'guitar_string_winder_pin',\n",
    "           'guitar_capo_string',\n",
    "           'daddario_electric_guitar_string',\n",
    "           'acoustic_daddario_guitar_tring',\n",
    "           'guitar_stand_strap',\n",
    "           'guitar_leather_strap',\n",
    "           'guitar_snark_tuner1',\n",
    "           'guitar_snark_tuner2',\n",
    "           'guitar_snark_tuner3']\n",
    "\n",
    "# Using 'album_name' as the column name and equating it to the list\n",
    "df_grouped2['album_name'] = album_name\n",
    "df_grouped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df1 = df1[(df1.Sentiment_Type == 'NEGATIVE')]\n",
    "negative1 = negative_df1[('Sentiment_Type')].groupby(negative_df1['asin']).value_counts()\n",
    "neg_sent1 = pd.DataFrame({'count':((negative1.sort_values(ascending = False)).head(10))}).reset_index()\n",
    "#neg_sent1.plot(kind='bar',title=\"Negative Sentiment Analysis\");\n",
    "neg_sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5524b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df2 = df2[(df2.Sentiment_Type == 'NEGATIVE')]\n",
    "negative2 = negative_df2[('Sentiment_Type')].groupby(negative_df2['asin']).value_counts()\n",
    "neg_sent2 = pd.DataFrame({'count':((negative2.sort_values(ascending = False)).head(10))}).reset_index()\n",
    "#neg_sent2.plot(kind='bar',title=\"Negative Sentiment Analysis\");\n",
    "neg_sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = neg_sent1.asin\n",
    "neg_df1 = pd.merge(df1, a,on='asin')\n",
    "neg_df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable = ['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "neg_df1['review'] = neg_df1['review'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.crosstab(neg_df1.asin, neg_df1.Sentiment_Type, rownames = ['asin'], colnames = ['Sentiment_Type'])\n",
    "c.plot(kind = 'bar', figsize= (15, 3))\n",
    "plt.title ('product code vs sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3150e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped3 = neg_df1[['asin','review']].groupby(by='asin').agg(lambda x:' '.join(x))\n",
    "df_grouped3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word')\n",
    "data = cv.fit_transform(df_grouped3['review'])\n",
    "df_dtm3 = pd.DataFrame(data.toarray(), columns = cv.get_feature_names())\n",
    "df_dtm3.index = df_grouped3.index\n",
    "df_dtm3 = df_dtm3.transpose()\n",
    "df_dtm3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ead115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting word cloud for each product\n",
    "for index,product in enumerate(df_dtm3.columns):\n",
    "    review_wordcloud(df_dtm3[product].sort_values(ascending=False),product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list that is to be converted into a column\n",
    "reason = ['eminem rap not good track',\n",
    "           'durust band limp bizkit band not good lyric',\n",
    "           'eminem rap track not good lyric',\n",
    "           'ja rule bad rap pop track',\n",
    "           'cent rap not good beat',\n",
    "           'gunit llyod cent track beat not good',\n",
    "           'not like eminem',\n",
    "           'game not like rap',\n",
    "           'song beat not like cent track',\n",
    "           'gunit tony yayo not good']\n",
    "\n",
    "# Using 'album_name' as the column name and equating it to the list\n",
    "df_grouped3['reason'] = reason\n",
    "df_grouped3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.fit_transform(df_grouped3.reason)\n",
    "sum_words = words.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "wordcloud = WordCloud(background_color = 'black', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Vocabulary from Negative Reviews\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16379828",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = neg_sent2.asin\n",
    "neg_df2 = pd.merge(df2, b,on='asin')\n",
    "neg_df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable = ['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "neg_df2['review'] = neg_df2['review'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb102bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.crosstab(neg_df2.asin, neg_df2.Sentiment_Type, rownames = ['asin'], colnames = ['Sentiment_Type'])\n",
    "d.plot(kind = 'bar', figsize= (15, 3))\n",
    "plt.title ('product code vs sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7df581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped4 = neg_df2[['asin','review']].groupby(by='asin').agg(lambda x:' '.join(x))\n",
    "df_grouped4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc79564",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word')\n",
    "data = cv.fit_transform(df_grouped4['review'])\n",
    "df_dtm4 = pd.DataFrame(data.toarray(), columns = cv.get_feature_names())\n",
    "df_dtm4.index = df_grouped4.index\n",
    "df_dtm4 = df_dtm4.transpose()\n",
    "df_dtm4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce126b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting word cloud for each product\n",
    "for index,product in enumerate(df_dtm4.columns):\n",
    "    review_wordcloud(df_dtm4[product].sort_values(ascending=False),product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3be9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list that is to be converted into a column\n",
    "reason = ['mic filter not work',\n",
    "           'tortex not good',\n",
    "           'guitar string oil fret',\n",
    "           'guitar winder string not work',\n",
    "           'guitar holder not work',\n",
    "           'cable quality not fit',\n",
    "           'guitar strap cheap',\n",
    "           'leather strap not great',\n",
    "           'mic stand not good',\n",
    "           'guitar tuner not easy use']\n",
    "\n",
    "# Using 'album_name' as the column name and equating it to the list\n",
    "df_grouped4['reason'] = reason\n",
    "df_grouped4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.fit_transform(df_grouped4.reason)\n",
    "sum_words = words.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "wordcloud = WordCloud(background_color = 'black', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Vocabulary from Negative Reviews\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b6be4",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba48ce",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88feed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping columns which seems not to directly effect the prediction\n",
    "df_a = df1.drop(['reviewerID',\n",
    "                 'asin',\n",
    "                 'reviewerName', \n",
    "                'helpful', \n",
    "                'reviewText', \n",
    "                'summary', \n",
    "                'unixReviewTime', \n",
    "                'reviewTime', \n",
    "                'review', \n",
    "                'help_num', \n",
    "                'help_den', \n",
    "                'help_slot',\n",
    "                 'year',\n",
    "                'Polarity'], axis = 1)\n",
    "df_a.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba40cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(df_a.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "df_a.Sentiment_Type = encoder_1.transform(df_a.Sentiment_Type)\n",
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for age to exited\n",
    "sns.kdeplot(df_a[df_a['Sentiment_Type'] == 0]['overall'], shade = True, color = 'green');\n",
    "sns.kdeplot(df_a[df_a['Sentiment_Type'] == 1]['overall'], shade = True, color = 'red');\n",
    "sns.kdeplot(df_a[df_a['Sentiment_Type'] == 2]['overall'], shade = True, color = 'blue');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features and variables\n",
    "X = df_a.drop(columns = 'Sentiment_Type', axis = 1)\n",
    "y = df_a.Sentiment_Type\n",
    "\n",
    "# Train-Test Separation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a7494",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# creating a logistic regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# performing predictions on the test dataset\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy calculation\n",
    "print('ACCURACY OF LOGISTIC REGRESSION MODEL:', round(logreg.score(X_test, y_test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893df6a",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a97a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# creating an user defined function to create a slider for k-values, to find the best accuracy\n",
    "def knn(k):\n",
    "    data = df_a\n",
    "    \n",
    "    # the data\n",
    "    X = df_a.drop(columns = 'Sentiment_Type', axis =1)\n",
    "    y = df_a.Sentiment_Type\n",
    "\n",
    "    # learning the classifier\n",
    "    kn = neighbors.KNeighborsClassifier(k)\n",
    "    kn.fit(X, y)\n",
    "    print(\"ACCURACY OF THE MODEL:\", round(kn.score(X_test, y_test), 2))\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from sklearn import neighbors\n",
    "k_value = interactive(knn, k=(2, 20, 2))\n",
    "\n",
    "k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f549e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reperforming the knn algorithm with required value of k = 4\n",
    "kn = neighbors.KNeighborsClassifier(4)\n",
    "kn.fit(X, y)\n",
    "print(\"ACCURACY OF KNN MODEL:\", round(kn.score(X_test, y_test), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate model with Kfold stratified cross validation\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Stratified K-Folds cross-validator\n",
    "kfold = StratifiedKFold(n_splits=2) #Number of folds. Must be at least 2.\n",
    "                                    #Returns the number of splitting iterations in the cross-validator.\n",
    "\n",
    "# Modeling step Test differents algorithms \n",
    "random_state = 30\n",
    "\n",
    "classifiers = []\n",
    "classifiers.append(LogisticRegression())\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold))\n",
    "\n",
    "cv_means = []\n",
    "\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    \n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means, \"Classification_Algorithm\":[\"LogisticRegression\", \"KNeighboors\"]})\n",
    "\n",
    "g = sns.barplot(cv_means, \"Classification_Algorithm\", data = cv_res, palette = \"Set2\")\n",
    "g.set_xlabel(\"Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61cfab",
   "metadata": {},
   "source": [
    "# k means clustering on digital music dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping columns which seems not to directly effect the prediction\n",
    "df_a = df1.drop(['reviewerID',\n",
    "                 'reviewerName', \n",
    "                'helpful', \n",
    "                'reviewText', \n",
    "                'summary', \n",
    "                'unixReviewTime', \n",
    "                'reviewTime', \n",
    "                'review', \n",
    "                'help_num', \n",
    "                'help_den', \n",
    "                'help_slot',\n",
    "                 'year',\n",
    "                'Polarity'], axis = 1)\n",
    "df_a.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa131e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(df_a.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "df_a.Sentiment_Type = encoder_1.transform(df_a.Sentiment_Type)\n",
    "#encoder_1.fit(df_a.asin)\n",
    "#print(encoder_1.classes_)\n",
    "#df_a.asin = encoder_1.transform(df_a.asin)\n",
    "#df_a['product_code'] = encoder_1.transform(df_a.asin)\n",
    "print(df_a.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2a5b27d",
   "metadata": {},
   "source": [
    "product_encoder_dm = df_a\n",
    "product_encoder_dm.to_csv('product_encoder_dm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_a = df_a[['overall', 'help_ratio', 'Sentiment_Type', 'product_code']]\n",
    "df_a = df_a[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "df_a.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heap map will show the correlation of columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5, 3))\n",
    "sns.heatmap(df_a.corr(), cmap = 'rainbow', annot = True, linewidth = 5).set_title('correlation  of columns via heat map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44ac1bc4",
   "metadata": {},
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "db = DBSCAN().fit(df_a)\n",
    "\n",
    "df_a['Labels'] = db.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(df_a['overall'], df_a['help_ratio'], hue=df_a['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(db.labels_).shape[0]))\n",
    "plt.title('DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ea7fdec",
   "metadata": {},
   "source": [
    "review_scale1 = df_a\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "scale_columns1 = ['overall', \n",
    "                 'help_ratio', \n",
    "                 'Sentiment_Type']\n",
    "\n",
    "review_scale1[scale_columns1] = scale.fit_transform(df_a[scale_columns1])\n",
    "review_scale1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de915e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELBOW METHOD\n",
    "\n",
    "distorsions = []\n",
    "\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df_a)\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.plot(range(2, 10), distorsions)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0febac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K MEANS\n",
    "\n",
    "# overall and sentiment type\n",
    "\n",
    "km = KMeans(n_clusters = 4).fit(df_a)\n",
    "\n",
    "df_a['Labels'] = km.labels_\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(df_a['overall'], df_a['help_ratio'], hue = df_a['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(km.labels_).shape[0]))\n",
    "plt.title('KMeans:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8be784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a.head(1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05facd0f",
   "metadata": {},
   "source": [
    "# AGGLOMERATIVE CLUSTERING\n",
    "df_a = df_a[['overall', 'help_ratio', 'Sentiment_Type', 'product_code']]\n",
    "n_clusters = [3]\n",
    "n_link = ['average']\n",
    "\n",
    "# overall and sentiment type\n",
    "\n",
    "for c in n_clusters:\n",
    "    linkage = n_link\n",
    "    for l in linkage:\n",
    "        model = AgglomerativeClustering(n_clusters = c, linkage = l)\n",
    "        model = model.fit(df_a)\n",
    "        print(model)\n",
    "        df_a['Labels'] = model.labels_\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.scatterplot(df_a['overall'], df_a['Sentiment_Type'], hue = df_a['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(model.labels_).shape[0]))\n",
    "        plt.title('Agglomerative:')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff74fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values of label column\n",
    "df_a.Labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e96c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bins for labels and adding the same to dataframe\n",
    "\n",
    "bins = [-1, 0, 1, 2, 3]\n",
    "slot = ['Good_Products',\n",
    "        'Quality_Products',\n",
    "        'Average_Products',\n",
    "        'Bad_Products']\n",
    "\n",
    "df_a['REVIEWER_CATEGORY'] = pd.cut(df_a['Labels'], bins = bins, labels = slot)\n",
    "\n",
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a['REVIEWER_CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bfd185a",
   "metadata": {},
   "source": [
    "df_a.to_csv('product_cluster_dm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dde9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Bad_Products') & (df_a.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_a[(df_a.REVIEWER_CATEGORY == 'Bad_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Bad_Products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Bad_Products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca845cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Quality_Products') & (df_a.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_a[(df_a.REVIEWER_CATEGORY == 'Quality_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Quality_Products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Quality_Products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74399e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Good_Products') & (df_a.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_a[(df_a.REVIEWER_CATEGORY == 'Good_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdf118",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Good_Products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Good_Products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9be002",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Average_Products') & (df_a.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_a[(df_a.REVIEWER_CATEGORY == 'Average_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_a[(df_a.REVIEWER_CATEGORY == 'Average_Products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Average_Products');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f3bee",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ab5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping columns which seems not to directly effect the prediction\n",
    "df_b = df2.drop(['reviewerID',\n",
    "                 'asin',\n",
    "                 'reviewerName', \n",
    "                'helpful', \n",
    "                'reviewText', \n",
    "                'summary', \n",
    "                'unixReviewTime', \n",
    "                'reviewTime', \n",
    "                'review', \n",
    "                'help_num', \n",
    "                'help_den', \n",
    "                'help_slot',\n",
    "                 'year',\n",
    "                'Polarity'], axis = 1)\n",
    "df_b.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac08771",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(df_b.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "df_b.Sentiment_Type = encoder_1.transform(df_b.Sentiment_Type)\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for age to exited\n",
    "sns.kdeplot(df_b[df_b['Sentiment_Type'] == 0]['overall'], shade = True, color = 'green');\n",
    "sns.kdeplot(df_b[df_b['Sentiment_Type'] == 1]['overall'], shade = True, color = 'red');\n",
    "sns.kdeplot(df_b[df_b['Sentiment_Type'] == 2]['overall'], shade = True, color = 'blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features and variables\n",
    "X = df_b.drop(columns = 'Sentiment_Type', axis = 1)\n",
    "y = df_b.Sentiment_Type\n",
    "\n",
    "# Train-Test Separation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e925c9",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182819b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# creating a logistic regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# performing predictions on the test dataset\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy calculation\n",
    "print('ACCURACY OF LOGISTIC REGRESSION MODEL:', round(logreg.score(X_test, y_test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c36b8b",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# creating an user defined function to create a slider for k-values, to find the best accuracy\n",
    "def knn(k):\n",
    "    data = df_b\n",
    "    \n",
    "    # the data\n",
    "    X = df_b.drop(columns = 'Sentiment_Type', axis =1)\n",
    "    y = df_b.Sentiment_Type\n",
    "\n",
    "    # learning the classifier\n",
    "    kn = neighbors.KNeighborsClassifier(k)\n",
    "    kn.fit(X, y)\n",
    "    print(\"ACCURACY OF THE MODEL:\", round(kn.score(X_test, y_test), 2))\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from sklearn import neighbors\n",
    "k_value = interactive(knn, k=(2, 20, 2))\n",
    "\n",
    "k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543715a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reperforming the knn algorithm with required value of k = 4\n",
    "kn = neighbors.KNeighborsClassifier(4)\n",
    "kn.fit(X, y)\n",
    "print(\"ACCURACY OF KNN MODEL:\", round(kn.score(X_test, y_test), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403225e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate model with Kfold stratified cross validation\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Stratified K-Folds cross-validator\n",
    "kfold = StratifiedKFold(n_splits=2) #Number of folds. Must be at least 2.\n",
    "                                    #Returns the number of splitting iterations in the cross-validator.\n",
    "\n",
    "# Modeling step Test differents algorithms \n",
    "random_state = 30\n",
    "\n",
    "classifiers = []\n",
    "classifiers.append(LogisticRegression())\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold))\n",
    "\n",
    "cv_means = []\n",
    "\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    \n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means, \"Classification_Algorithm\":[\"LogisticRegression\", \"KNeighboors\"]})\n",
    "\n",
    "g = sns.barplot(cv_means, \"Classification_Algorithm\", data = cv_res, palette = \"Set2\")\n",
    "g.set_xlabel(\"Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4de14",
   "metadata": {},
   "source": [
    "# k means clustering on musical instruments dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping columns which seems not to directly effect the prediction\n",
    "df_b = df2.drop(['reviewerID',\n",
    "                 'reviewerName', \n",
    "                'helpful', \n",
    "                'reviewText', \n",
    "                'summary', \n",
    "                'unixReviewTime', \n",
    "                'reviewTime', \n",
    "                'review', \n",
    "                'help_num', \n",
    "                'help_den', \n",
    "                'help_slot',\n",
    "                 'year',\n",
    "                'Polarity'], axis = 1)\n",
    "df_b.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfade0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(df_b.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "df_b.Sentiment_Type = encoder_1.transform(df_b.Sentiment_Type)\n",
    "#encoder_1.fit(df_b.asin)\n",
    "#print(encoder_1.classes_)\n",
    "#df_a.asin = encoder_1.transform(df_a.asin)\n",
    "#df_b['product_code'] = encoder_1.transform(df_b.asin)\n",
    "print(df_b.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "211ef56d",
   "metadata": {},
   "source": [
    "product_encoder_mi = df_b\n",
    "product_encoder_mi.to_csv('product_encoder_mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_b = df_b[['overall', 'help_ratio', 'Sentiment_Type', 'product_code']]\n",
    "df_b = df_b[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "df_b.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cb6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heap map will show the correlation of columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5, 3))\n",
    "sns.heatmap(df_b.corr(), cmap = 'rainbow', annot = True, linewidth = 5).set_title('correlation  of columns via heat map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cde9b",
   "metadata": {},
   "source": [
    "# dbscan"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ba7a90f",
   "metadata": {},
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "db = DBSCAN().fit(df_b)\n",
    "\n",
    "df_b['Labels'] = db.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(df_b['overall'], df_b['help_ratio'], hue=df_b['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(db.labels_).shape[0]))\n",
    "plt.title('DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b930ed",
   "metadata": {},
   "source": [
    "# AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f57ad01",
   "metadata": {},
   "source": [
    "# AGGLOMERATIVE CLUSTERING\n",
    "\n",
    "n_clusters = [3]\n",
    "n_link = ['average']\n",
    "\n",
    "# overall and sentiment type\n",
    "\n",
    "for c in n_clusters:\n",
    "    linkage = n_link\n",
    "    for l in linkage:\n",
    "        model = AgglomerativeClustering(n_clusters = c, linkage = l)\n",
    "        model = model.fit(review_scale2)\n",
    "        print(model)\n",
    "        review_scale2['Labels'] = model.labels_\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.scatterplot(review_scale2['overall'], review_scale2['Sentiment_Type'], hue = review_scale2['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(model.labels_).shape[0]))\n",
    "        plt.title('Agglomerative:')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93696f5e",
   "metadata": {},
   "source": [
    "review_scale2 = df_b\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "scale_columns2 = ['overall', \n",
    "                 'help_ratio', \n",
    "                 'Sentiment_Type']\n",
    "\n",
    "review_scale2[scale_columns2] = scale.fit_transform(df_b[scale_columns2])\n",
    "review_scale2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELBOW METHOD\n",
    "\n",
    "distorsions = []\n",
    "\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df_b)\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.plot(range(2, 10), distorsions)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315babed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K MEANS\n",
    "\n",
    "# overall and sentiment type\n",
    "\n",
    "km = KMeans(n_clusters = 4).fit(df_b)\n",
    "\n",
    "df_b['Labels'] = km.labels_\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(df_b['overall'], df_b['help_ratio'], hue = df_b['Labels'], \n",
    "                palette=sns.color_palette('hls', np.unique(km.labels_).shape[0]))\n",
    "plt.title('KMeans:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values of label column\n",
    "df_b.Labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd781e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bins for labels and adding the same to dataframe\n",
    "\n",
    "bins = [-1, 0, 1, 2, 3]\n",
    "slot = ['Good_Products',\n",
    "        'Average_products',\n",
    "        'Quality_Products',\n",
    "        'Bad_Products']\n",
    "\n",
    "df_b['REVIEWER_CATEGORY'] = pd.cut(df_b['Labels'], bins = bins, labels = slot)\n",
    "\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9947b91",
   "metadata": {},
   "source": [
    "df_b['REVIEWER_CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6577015",
   "metadata": {},
   "source": [
    "df_b.to_csv('product_cluster_mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da89994",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Good_Products') & (df_b.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_b[(df_b.REVIEWER_CATEGORY == 'Good_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1352649",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Good_Products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Good_Products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Quality_Products') & (df_b.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_b[(df_b.REVIEWER_CATEGORY == 'Quality_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26212378",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Quality_Products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Quality_Products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Bad_Products') & (df_b.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_b[(df_b.REVIEWER_CATEGORY == 'Bad_Products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Average_products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Average_products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Average_products') & (df_b.help_ratio >= 0.5)]\n",
    "(xy.shape[0]/len(df_b[(df_b.REVIEWER_CATEGORY == 'Average_products')])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = df_b[(df_b.REVIEWER_CATEGORY == 'Average_products')]\n",
    "plt.scatter(xy.overall, xy.help_ratio)\n",
    "plt.xlabel('overall')\n",
    "plt.ylabel('help_ratio')\n",
    "plt.title('Average_products');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8c768",
   "metadata": {},
   "source": [
    "# TIME SERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e42af1",
   "metadata": {},
   "source": [
    "### digital music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14540e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatype\n",
    "print(type(df1.reviewTime))\n",
    "\n",
    "dm1 = df1.sort_values(by='reviewTime')\n",
    "\n",
    "dm1 = dm1.set_index('reviewTime')\n",
    "\n",
    "dm1 = dm1[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "dm1 = dm1[(dm1.Sentiment_Type == 'POSITIVE')]\n",
    "\n",
    "\n",
    "\n",
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(dm1.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "dm1.Sentiment_Type = encoder_1.transform(dm1.Sentiment_Type)\n",
    "dm1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd285d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data with respect to 7 days\n",
    "# D = daily\n",
    "dm1 = dm1.resample('7D').sum()\n",
    "#dm1 = dm1[(dm1.Polarity > 0)]\n",
    "dm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1 = dm1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce653c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# seasonal_decompose\n",
    "fig,ax=plt.subplots(3,1,figsize=(20,20))\n",
    "\n",
    "result=seasonal_decompose(dm1['overall'],period=52,extrapolate_trend='freq')\n",
    "result.trend.plot(ax=ax[0])\n",
    "ax[0].set_title(\"Trend\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_title(\"Seasonal\")\n",
    "\n",
    "result.resid.plot(ax=ax[2])\n",
    "ax[2].set_title(\"Random\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 560)]\n",
    "test_df1 = dm1[slice(560,845)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3defb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"------------------------------------TRAIN DATA----------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "train_df1['overall'].plot(ax=ax[0])\n",
    "train_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# TEST\n",
    "print(\"-------------------------------------TEST DATA------------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "test_df1['overall'].plot(ax=ax[0])\n",
    "test_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ded16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1['overall']\n",
    "dm1_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot shows stationarity\n",
    "dm1_overall.plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d99d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dickey-fuller test for stationarity\n",
    "def checkStationarity(data):\n",
    "    pvalue = adfuller(data)[1]\n",
    "    if(pvalue>0.05):\n",
    "        msg = 'p-value={}. Data is not stationary. Make the data stationary before model building.'.format(pvalue)\n",
    "    else:\n",
    "        msg='p-value={}. Data is stationary. Proceed to model building'.format(pvalue)\n",
    "        \n",
    "    return(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data for stationarity\n",
    "checkStationarity(dm1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 12-level differencing, since the data is seasonal\n",
    "dm1_overall['diff12'] = dm1_overall.diff(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9505ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test on differenced data\n",
    "res = adfuller(dm1_overall['diff12'].dropna())\n",
    "if res[1] < 0.05:\n",
    "    print('Data is stationary. Proceed to model building')\n",
    "else:\n",
    "    print('Data is not stationary. Make the data stationary before model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326adde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall['diff12'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 560)]\n",
    "test_df1 = dm1[slice(560,844)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1491da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = auto_arima(dm1_overall, start_p = 0, max_p = 2, start_q = 0, max_q = 2, seasonal = False, trace = True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1eef12",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ARIMA model\n",
    "# start with initial values for p and q based on auto_arima recommendation\n",
    "p = 1; d = 0; q = 1\n",
    "model_1 = ARIMA(dm1['overall'],order=(p,d,q)).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7217a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the model\n",
    "# predictions\n",
    "start = len(train_df1) \n",
    "end = len(train_df1) + len(test_df1) - 1\n",
    "\n",
    "print('start = {}, end = {}'.format(start,end))\n",
    "\n",
    "predictions1 = model_1.predict(start,end,typ='levels')\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20705cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate actual, predicted, and error values together\n",
    "# actual vs predicted values\n",
    "# print(\"test = {}, predicted = {}\".format(len(test), len(predictions) ))\n",
    "actual = []; pred = []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    actual.append(test_df1['overall'][i])\n",
    "    pred.append(predictions1[i])\n",
    "\n",
    "df_res = pd.DataFrame({'actual':actual, 'predicted':pred})\n",
    "df_res['error'] = df_res.actual - df_res.predicted\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5004cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Jenkins test to check model's goodness\n",
    "# LJung-Box test\n",
    "pvalue = sm.stats.acorr_ljungbox(model_1.resid,lags=[1],return_df=True)['lb_pvalue'].values\n",
    "if pvalue < 0.05:\n",
    "    print(\"Reject H0. Bad model\")\n",
    "else:\n",
    "    print(\"Accept H0. Good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error terms\n",
    "# MSE\n",
    "msg = 'ARIMA Model. Order=(' + str(p) + ',' + str(d) + ',' + str(q) + ')'\n",
    "mse = mean_squared_error(df_res.actual, df_res.predicted)\n",
    "print(msg + \"\\n\\tMSE = {}\\n\\tRMSE = {}\".format(mse,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.actual.plot(figsize=(10, 5),legend=True)\n",
    "df_res.predicted.plot(legend=True)\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0609b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "m1 = ARIMA(test_df1['overall'],order=(p,d,q)).fit()\n",
    "fcast = m1.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f31198",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['overall'].plot(figsize=(10, 5),legend=True)\n",
    "fcast.plot(legend=True)\n",
    "plt.ylabel('sum of positive reviews')\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95058d84",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d49300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal data, use the SARIMAX. start with initial values for p,d,q\n",
    "p=1; q=1; d=0\n",
    "m1 = sm.tsa.statespace.SARIMAX(dm1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a58f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = m1.predict(start=560,end=847,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'actual':dm1.overall[560:],'predicted':predictions})\n",
    "df_res['err'] = df_res.actual - df_res.predicted\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8508fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mean_squared_error(df_res.actual,df_res.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_res[['actual','predicted']].plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f580b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "p=1; q=1; d=0\n",
    "m2 = sm.tsa.statespace.SARIMAX(test_df1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()\n",
    "fcast = m2.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels').rename('Forecast')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33939bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1['overall'].plot(figsize=(10,5),legend=True, linewidth=1.0)\n",
    "plt.ylabel('sum of positive reviews')\n",
    "fcast.plot(legend=True, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb27b7",
   "metadata": {},
   "source": [
    "# digital music: negative time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b702346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatype\n",
    "print(type(df1.reviewTime))\n",
    "\n",
    "dm1 = df1.sort_values(by='reviewTime')\n",
    "\n",
    "dm1 = dm1.set_index('reviewTime')\n",
    "\n",
    "dm1 = dm1[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "dm1 = dm1[(dm1.Sentiment_Type == 'NEGATIVE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(dm1.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "dm1.Sentiment_Type = encoder_1.transform(dm1.Sentiment_Type)\n",
    "dm1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data with respect to 7 days\n",
    "# D = daily\n",
    "dm1 = dm1.resample('7D').sum()\n",
    "#dm1 = dm1[(dm1.Polarity != 0)]\n",
    "dm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a054b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1 = dm1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51709109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# seasonal_decompose\n",
    "fig,ax=plt.subplots(3,1,figsize=(20,20))\n",
    "\n",
    "result=seasonal_decompose(dm1['overall'],period=52,extrapolate_trend='freq')\n",
    "result.trend.plot(ax=ax[0])\n",
    "ax[0].set_title(\"Trend\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_title(\"Seasonal\")\n",
    "\n",
    "result.resid.plot(ax=ax[2])\n",
    "ax[2].set_title(\"Random\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee57726",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 560)]\n",
    "test_df1 = dm1[slice(560,843)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e691e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"------------------------------------TRAIN DATA----------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "train_df1['overall'].plot(ax=ax[0])\n",
    "train_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# TEST\n",
    "print(\"-------------------------------------TEST DATA------------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "test_df1['overall'].plot(ax=ax[0])\n",
    "test_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1['overall']\n",
    "dm1_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0402145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot shows stationarity\n",
    "dm1_overall.plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5465f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dickey-fuller test for stationarity\n",
    "def checkStationarity(data):\n",
    "    pvalue = adfuller(data)[1]\n",
    "    if(pvalue>0.05):\n",
    "        msg = 'p-value={}. Data is not stationary. Make the data stationary before model building.'.format(pvalue)\n",
    "    else:\n",
    "        msg='p-value={}. Data is stationary. Proceed to model building'.format(pvalue)\n",
    "        \n",
    "    return(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data for stationarity\n",
    "checkStationarity(dm1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 12-level differencing, since the data is seasonal\n",
    "dm1_overall['diff12'] = dm1_overall.diff(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff79db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test on differenced data\n",
    "res = adfuller(dm1_overall['diff12'].dropna())\n",
    "if res[1] < 0.05:\n",
    "    print('Data is stationary. Proceed to model building')\n",
    "else:\n",
    "    print('Data is not stationary. Make the data stationary before model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c680ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall['diff12'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ede18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 560)]\n",
    "test_df1 = dm1[slice(560,831)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = auto_arima(dm1_overall, start_p = 0, max_p = 2, start_q = 0, max_q = 2, seasonal = False, trace = True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9e878",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ARIMA model\n",
    "# start with initial values for p and q based on auto_arima recommendation\n",
    "p = 1; d = 0; q = 1\n",
    "model_1 = ARIMA(dm1['overall'],order=(p,d,q)).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the model\n",
    "# predictions\n",
    "start = len(train_df1) \n",
    "end = len(train_df1) + len(test_df1) - 1\n",
    "\n",
    "print('start = {}, end = {}'.format(start,end))\n",
    "\n",
    "predictions1 = model_1.predict(start,end,typ='levels')\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate actual, predicted, and error values together\n",
    "# actual vs predicted values\n",
    "# print(\"test = {}, predicted = {}\".format(len(test), len(predictions) ))\n",
    "actual = []; pred = []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    actual.append(test_df1['overall'][i])\n",
    "    pred.append(predictions1[i])\n",
    "\n",
    "df_res = pd.DataFrame({'actual':actual, 'predicted':pred})\n",
    "df_res['error'] = df_res.actual - df_res.predicted\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce527ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e34c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Jenkins test to check model's goodness\n",
    "# LJung-Box test\n",
    "pvalue = sm.stats.acorr_ljungbox(model_1.resid,lags=[1],return_df=True)['lb_pvalue'].values\n",
    "if pvalue < 0.05:\n",
    "    print(\"Reject H0. Bad model\")\n",
    "else:\n",
    "    print(\"Accept H0. Good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error terms\n",
    "# MSE\n",
    "msg = 'ARIMA Model. Order=(' + str(p) + ',' + str(d) + ',' + str(q) + ')'\n",
    "mse = mean_squared_error(df_res.actual, df_res.predicted)\n",
    "print(msg + \"\\n\\tMSE = {}\\n\\tRMSE = {}\".format(mse,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.actual.plot(figsize=(10, 5),legend=True)\n",
    "df_res.predicted.plot(legend=True)\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "m1 = ARIMA(test_df1['overall'],order=(p,d,q)).fit()\n",
    "fcast = m1.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['overall'].plot(figsize=(10, 5),legend=True)\n",
    "fcast.plot(legend=True)\n",
    "plt.ylabel('sum of negative reviews')\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f778a",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal data, use the SARIMAX. start with initial values for p,d,q\n",
    "p=1; q=1; d=0\n",
    "m1 = sm.tsa.statespace.SARIMAX(dm1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = m1.predict(start=560,end=842,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80734bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'actual':dm1.overall[560:],'predicted':predictions})\n",
    "df_res['err'] = df_res.actual - df_res.predicted\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36550184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mean_squared_error(df_res.actual,df_res.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad98c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_res[['actual','predicted']].plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "p=1; q=1; d=0\n",
    "m2 = sm.tsa.statespace.SARIMAX(test_df1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()\n",
    "fcast = m2.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels').rename('Forecast')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1['overall'].plot(figsize=(10,5),legend=True, linewidth=1.0)\n",
    "plt.ylabel('sum of negative reviews')\n",
    "fcast.plot(legend=True, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017d1c3",
   "metadata": {},
   "source": [
    "# digital music: neutral time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3465578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatype\n",
    "print(type(df1.reviewTime))\n",
    "\n",
    "dm1 = df1.sort_values(by='reviewTime')\n",
    "\n",
    "dm1 = dm1.set_index('reviewTime')\n",
    "\n",
    "dm1 = dm1[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "dm1 = dm1[(dm1.Sentiment_Type == 'NEUTRAL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3148d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(dm1.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "dm1.Sentiment_Type = encoder_1.transform(dm1.Sentiment_Type)\n",
    "dm1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6aef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data with respect to 7 days\n",
    "# D = daily\n",
    "dm1 = dm1.resample('7D').sum()\n",
    "#dm1 = dm1[(dm1.Polarity != 0)]\n",
    "dm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d385b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1 = dm1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11903c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d87859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# seasonal_decompose\n",
    "fig,ax=plt.subplots(3,1,figsize=(20,20))\n",
    "\n",
    "result=seasonal_decompose(dm1['overall'],period=52,extrapolate_trend='freq')\n",
    "result.trend.plot(ax=ax[0])\n",
    "ax[0].set_title(\"Trend\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_title(\"Seasonal\")\n",
    "\n",
    "result.resid.plot(ax=ax[2])\n",
    "ax[2].set_title(\"Random\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd15044",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 560)]\n",
    "test_df1 = dm1[slice(560,798)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0af227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"------------------------------------TRAIN DATA----------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "train_df1['overall'].plot(ax=ax[0])\n",
    "train_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# TEST\n",
    "print(\"-------------------------------------TEST DATA------------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "test_df1['overall'].plot(ax=ax[0])\n",
    "test_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1['overall']\n",
    "dm1_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acfb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot shows stationarity\n",
    "dm1_overall.plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dickey-fuller test for stationarity\n",
    "def checkStationarity(data):\n",
    "    pvalue = adfuller(data)[1]\n",
    "    if(pvalue>0.05):\n",
    "        msg = 'p-value={}. Data is not stationary. Make the data stationary before model building.'.format(pvalue)\n",
    "    else:\n",
    "        msg='p-value={}. Data is stationary. Proceed to model building'.format(pvalue)\n",
    "        \n",
    "    return(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data for stationarity\n",
    "checkStationarity(dm1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a94e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 12-level differencing, since the data is seasonal\n",
    "dm1_overall['diff12'] = dm1_overall.diff(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87577222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test on differenced data\n",
    "res = adfuller(dm1_overall['diff12'].dropna())\n",
    "if res[1] < 0.05:\n",
    "    print('Data is stationary. Proceed to model building')\n",
    "else:\n",
    "    print('Data is not stationary. Make the data stationary before model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e749cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall['diff12'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 560)]\n",
    "test_df1 = dm1[slice(560,785)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a26388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = auto_arima(dm1_overall, start_p = 0, max_p = 2, start_q = 0, max_q = 2, seasonal = False, trace = True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abaa15",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d01078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ARIMA model\n",
    "# start with initial values for p and q based on auto_arima recommendation\n",
    "p = 1; d = 0; q = 2\n",
    "model_1 = ARIMA(dm1['overall'],order=(p,d,q)).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the model\n",
    "# predictions\n",
    "start = len(train_df1) \n",
    "end = len(train_df1) + len(test_df1) - 1\n",
    "\n",
    "print('start = {}, end = {}'.format(start,end))\n",
    "\n",
    "predictions1 = model_1.predict(start,end,typ='levels')\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d260fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate actual, predicted, and error values together\n",
    "# actual vs predicted values\n",
    "# print(\"test = {}, predicted = {}\".format(len(test), len(predictions) ))\n",
    "actual = []; pred = []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    actual.append(test_df1['overall'][i])\n",
    "    pred.append(predictions1[i])\n",
    "\n",
    "df_res = pd.DataFrame({'actual':actual, 'predicted':pred})\n",
    "df_res['error'] = df_res.actual - df_res.predicted\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Jenkins test to check model's goodness\n",
    "# LJung-Box test\n",
    "pvalue = sm.stats.acorr_ljungbox(model_1.resid,lags=[1],return_df=True)['lb_pvalue'].values\n",
    "if pvalue < 0.05:\n",
    "    print(\"Reject H0. Bad model\")\n",
    "else:\n",
    "    print(\"Accept H0. Good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error terms\n",
    "# MSE\n",
    "msg = 'ARIMA Model. Order=(' + str(p) + ',' + str(d) + ',' + str(q) + ')'\n",
    "mse = mean_squared_error(df_res.actual, df_res.predicted)\n",
    "print(msg + \"\\n\\tMSE = {}\\n\\tRMSE = {}\".format(mse,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.actual.plot(figsize=(10, 5),legend=True)\n",
    "df_res.predicted.plot(legend=True)\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c21b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "m1 = ARIMA(test_df1['overall'],order=(p,d,q)).fit()\n",
    "fcast = m1.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730634c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['overall'].plot(figsize=(10, 5),legend=True)\n",
    "fcast.plot(legend=True)\n",
    "plt.ylabel('sum of positive reviews')\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37998c",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal data, use the SARIMAX. start with initial values for p,d,q\n",
    "p=1; q=2; d=0\n",
    "m1 = sm.tsa.statespace.SARIMAX(dm1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a10ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = m1.predict(start=560,end=797,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'actual':dm1.overall[560:],'predicted':predictions})\n",
    "df_res['err'] = df_res.actual - df_res.predicted\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mean_squared_error(df_res.actual,df_res.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_res[['actual','predicted']].plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "p=1; q=2; d=0\n",
    "m2 = sm.tsa.statespace.SARIMAX(test_df1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()\n",
    "fcast = m2.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels').rename('Forecast')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1['overall'].plot(figsize=(10,5),legend=True, linewidth=1.0)\n",
    "plt.ylabel('sum of neutral reviews')\n",
    "fcast.plot(legend=True, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751844a",
   "metadata": {},
   "source": [
    "### musical instrument: positive time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatype\n",
    "print(type(df2.reviewTime))\n",
    "\n",
    "dm2 = df2.sort_values(by='reviewTime')\n",
    "\n",
    "dm2 = dm2.set_index('reviewTime')\n",
    "\n",
    "dm2 = dm2[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "dm2 = dm2[(dm2.Sentiment_Type == 'POSITIVE')]\n",
    "\n",
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(dm2.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "dm2.Sentiment_Type = encoder_1.transform(dm2.Sentiment_Type)\n",
    "dm2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data with respect to 7 days\n",
    "# D = daily\n",
    "dm2 = dm2.resample('7D').sum()\n",
    "dm2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adacc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2 = dm2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal_decompose\n",
    "fig,ax=plt.subplots(3,1,figsize=(20,20))\n",
    "\n",
    "result=seasonal_decompose(dm2['overall'],period=52,extrapolate_trend='freq')\n",
    "result.trend.plot(ax=ax[0])\n",
    "ax[0].set_title(\"Trend\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_title(\"Seasonal\")\n",
    "\n",
    "result.resid.plot(ax=ax[2])\n",
    "ax[2].set_title(\"Random\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = dm2[slice(0, 350)]\n",
    "test_df2 = dm2[slice(350, 514)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee15519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"------------------------------------TRAIN DATA----------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "train_df2['overall'].plot(ax=ax[0])\n",
    "train_df2['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# TEST\n",
    "print(\"-------------------------------------TEST DATA------------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "test_df2['overall'].plot(ax=ax[0])\n",
    "test_df2['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2_overall = dm2['overall']\n",
    "dm2_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot shows stationarity\n",
    "dm2_overall.plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78132109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dickey-fuller test for stationarity\n",
    "def checkStationarity(data):\n",
    "    pvalue = adfuller(data)[1]\n",
    "    if(pvalue>0.05):\n",
    "        msg = 'p-value={}. Data is not stationary. Make the data stationary before model building.'.format(pvalue)\n",
    "    else:\n",
    "        msg='p-value={}. Data is stationary. Proceed to model building'.format(pvalue)\n",
    "        \n",
    "    return(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c964643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data for stationarity\n",
    "checkStationarity(dm2_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 12-level differencing, since the data is seasonal\n",
    "dm2_overall['diff12'] = dm2_overall.diff(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2_overall = dm2_overall.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ecd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test on differenced data\n",
    "res = adfuller(dm2_overall['diff12'].dropna())\n",
    "if res[1] < 0.05:\n",
    "    print('Data is stationary. Proceed to model building')\n",
    "else:\n",
    "    print('Data is not stationary. Make the data stationary before model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2_overall = dm2_overall['diff12'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fbdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = dm2[slice(0, 350)]\n",
    "test_df2 = dm2[slice(350, 502)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = auto_arima(dm2_overall, start_p = 0, max_p = 2, start_q = 0, max_q = 2, seasonal = False, trace = True)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ab935",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b29aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ARIMA model\n",
    "# start with initial values for p and q based on auto_arima recommendation\n",
    "p = 1; d = 0; q = 2\n",
    "model_1 = ARIMA(dm2['overall'],order=(p,d,q)).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the model\n",
    "# predictions\n",
    "start = len(train_df2) \n",
    "end = len(train_df2) + len(test_df2) - 1\n",
    "\n",
    "print('start = {}, end = {}'.format(start,end))\n",
    "\n",
    "predictions1 = model_1.predict(start,end,typ='levels')\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ac4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate actual, predicted, and error values together\n",
    "# actual vs predicted values\n",
    "# print(\"test = {}, predicted = {}\".format(len(test), len(predictions) ))\n",
    "actual = []; pred = []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    actual.append(test_df2['overall'][i])\n",
    "    pred.append(predictions1[i])\n",
    "\n",
    "df_res = pd.DataFrame({'actual':actual, 'predicted':pred})\n",
    "df_res['error'] = df_res.actual - df_res.predicted\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a03ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Jenkins test to check model's goodness\n",
    "# LJung-Box test\n",
    "pvalue = sm.stats.acorr_ljungbox(model_1.resid,lags=[1],return_df=True)['lb_pvalue'].values\n",
    "if pvalue < 0.05:\n",
    "    print(\"Reject H0. Bad model\")\n",
    "else:\n",
    "    print(\"Accept H0. Good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error terms\n",
    "# MSE\n",
    "msg = 'ARIMA Model. Order=(' + str(p) + ',' + str(d) + ',' + str(q) + ')'\n",
    "mse = mean_squared_error(df_res.actual, df_res.predicted)\n",
    "print(msg + \"\\n\\tMSE = {}\\n\\tRMSE = {}\".format(mse,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.actual.plot(figsize=(10,8),legend=True)\n",
    "df_res.predicted.plot(legend=True)\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "m1 = ARIMA(dm2['overall'],order=(p,d,q)).fit()\n",
    "fcast = m1.predict(start=len(dm2), end=len(dm2)+200, typ='levels')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d951130",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2['overall'].plot(figsize=(10,8),legend=True)\n",
    "fcast.plot(legend=True)\n",
    "plt.ylabel('sum of reviews')\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c491726",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal data, use the SARIMAX. start with initial values for p,d,q\n",
    "p=1; q=1; d=0\n",
    "m1 = sm.tsa.statespace.SARIMAX(dm2['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa83f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d574c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = m1.predict(start=350,end=513,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921276d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'actual':dm2.overall[350:],'predicted':predictions})\n",
    "df_res['err'] = df_res.actual - df_res.predicted\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mean_squared_error(df_res.actual,df_res.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_res[['actual','predicted']].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d475ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "p=1; q=2; d=0\n",
    "m2 = sm.tsa.statespace.SARIMAX(dm2['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()\n",
    "fcast = m2.predict(start=len(dm2), end=len(dm2)+300, typ='levels').rename('Forecast')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77481271",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2['overall'].plot(figsize=(10,5),legend=True, linewidth = 1.0)\n",
    "plt.ylabel('sum of positive reviewers')\n",
    "fcast.plot(legend=True, linewidth = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30b4ce",
   "metadata": {},
   "source": [
    "# musical instrument: negetive time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1646a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatype\n",
    "print(type(df2.reviewTime))\n",
    "\n",
    "dm1 = df2.sort_values(by='reviewTime')\n",
    "\n",
    "dm1 = dm1.set_index('reviewTime')\n",
    "\n",
    "dm1 = dm1[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "dm1 = dm1[(dm1.Sentiment_Type == 'NEGATIVE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c83e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(dm1.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "dm1.Sentiment_Type = encoder_1.transform(dm1.Sentiment_Type)\n",
    "dm1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data with respect to 7 days\n",
    "# D = daily\n",
    "dm1 = dm1.resample('7D').sum()\n",
    "#dm1 = dm1[(dm1.Polarity != 0)]\n",
    "dm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa13b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1 = dm1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e240e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# seasonal_decompose\n",
    "fig,ax=plt.subplots(3,1,figsize=(20,20))\n",
    "\n",
    "result=seasonal_decompose(dm1['overall'],period=52,extrapolate_trend='freq')\n",
    "result.trend.plot(ax=ax[0])\n",
    "ax[0].set_title(\"Trend\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_title(\"Seasonal\")\n",
    "\n",
    "result.resid.plot(ax=ax[2])\n",
    "ax[2].set_title(\"Random\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 250)]\n",
    "test_df1 = dm1[slice(250, 342)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"------------------------------------TRAIN DATA----------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "train_df1['overall'].plot(ax=ax[0])\n",
    "train_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# TEST\n",
    "print(\"-------------------------------------TEST DATA------------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "test_df1['overall'].plot(ax=ax[0])\n",
    "test_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1['overall']\n",
    "dm1_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot shows stationarity\n",
    "dm1_overall.plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c164b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dickey-fuller test for stationarity\n",
    "def checkStationarity(data):\n",
    "    pvalue = adfuller(data)[1]\n",
    "    if(pvalue>0.05):\n",
    "        msg = 'p-value={}. Data is not stationary. Make the data stationary before model building.'.format(pvalue)\n",
    "    else:\n",
    "        msg='p-value={}. Data is stationary. Proceed to model building'.format(pvalue)\n",
    "        \n",
    "    return(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af480ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data for stationarity\n",
    "checkStationarity(dm1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 12-level differencing, since the data is seasonal\n",
    "dm1_overall['diff12'] = dm1_overall.diff(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test on differenced data\n",
    "res = adfuller(dm1_overall['diff12'].dropna())\n",
    "if res[1] < 0.05:\n",
    "    print('Data is stationary. Proceed to model building')\n",
    "else:\n",
    "    print('Data is not stationary. Make the data stationary before model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067044bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall['diff12'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba517f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 250)]\n",
    "test_df1 = dm1[slice(250, 330)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = auto_arima(dm1_overall, start_p = 0, max_p = 2, start_q = 0, max_q = 2, seasonal = False, trace = True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844645b9",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6dab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ARIMA model\n",
    "# start with initial values for p and q based on auto_arima recommendation\n",
    "p = 1; d = 0; q = 1\n",
    "model_1 = ARIMA(dm1['overall'],order=(p,d,q)).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f00972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the model\n",
    "# predictions\n",
    "start = len(train_df1) \n",
    "end = len(train_df1) + len(test_df1) - 1\n",
    "\n",
    "print('start = {}, end = {}'.format(start,end))\n",
    "\n",
    "predictions1 = model_1.predict(start,end,typ='levels')\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924bd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate actual, predicted, and error values together\n",
    "# actual vs predicted values\n",
    "# print(\"test = {}, predicted = {}\".format(len(test), len(predictions) ))\n",
    "actual = []; pred = []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    actual.append(test_df1['overall'][i])\n",
    "    pred.append(predictions1[i])\n",
    "\n",
    "df_res = pd.DataFrame({'actual':actual, 'predicted':pred})\n",
    "df_res['error'] = df_res.actual - df_res.predicted\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6aec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Jenkins test to check model's goodness\n",
    "# LJung-Box test\n",
    "pvalue = sm.stats.acorr_ljungbox(model_1.resid,lags=[1],return_df=True)['lb_pvalue'].values\n",
    "if pvalue < 0.05:\n",
    "    print(\"Reject H0. Bad model\")\n",
    "else:\n",
    "    print(\"Accept H0. Good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bb754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error terms\n",
    "# MSE\n",
    "msg = 'ARIMA Model. Order=(' + str(p) + ',' + str(d) + ',' + str(q) + ')'\n",
    "mse = mean_squared_error(df_res.actual, df_res.predicted)\n",
    "print(msg + \"\\n\\tMSE = {}\\n\\tRMSE = {}\".format(mse,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.actual.plot(figsize=(10, 5),legend=True)\n",
    "df_res.predicted.plot(legend=True)\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f166f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "m1 = ARIMA(test_df1['overall'],order=(p,d,q)).fit()\n",
    "fcast = m1.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['overall'].plot(figsize=(10, 5),legend=True)\n",
    "fcast.plot(legend=True)\n",
    "plt.ylabel('sum of positive reviews')\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeaaaab",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal data, use the SARIMAX. start with initial values for p,d,q\n",
    "p=1; q=1; d=0\n",
    "m1 = sm.tsa.statespace.SARIMAX(dm1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = m1.predict(start=250,end=341,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f742c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'actual':dm1.overall[250:],'predicted':predictions})\n",
    "df_res['err'] = df_res.actual - df_res.predicted\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c084a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mean_squared_error(df_res.actual,df_res.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_res[['actual','predicted']].plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "p=1; q=1; d=0\n",
    "m2 = sm.tsa.statespace.SARIMAX(test_df1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()\n",
    "fcast = m2.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels').rename('Forecast')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a61180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1['overall'].plot(figsize=(10,5),legend=True, linewidth=1.0)\n",
    "plt.ylabel('sum of negative reviews')\n",
    "fcast.plot(legend=True, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b495e",
   "metadata": {},
   "source": [
    "# musical instruments: neutral time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatype\n",
    "print(type(df2.reviewTime))\n",
    "\n",
    "dm1 = df2.sort_values(by='reviewTime')\n",
    "\n",
    "dm1 = dm1.set_index('reviewTime')\n",
    "\n",
    "dm1 = dm1[['overall', 'help_ratio', 'Sentiment_Type']]\n",
    "dm1 = dm1[(dm1.Sentiment_Type == 'NEUTRAL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = preprocessing.LabelEncoder()\n",
    "\n",
    "encoder_1.fit(dm1.Sentiment_Type)\n",
    "print(encoder_1.classes_)\n",
    "dm1.Sentiment_Type = encoder_1.transform(dm1.Sentiment_Type)\n",
    "dm1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da608c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data with respect to 7 days\n",
    "# D = daily\n",
    "dm1 = dm1.resample('7D').sum()\n",
    "#dm1 = dm1[(dm1.Polarity != 0)]\n",
    "dm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbbfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1 = dm1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ae570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# seasonal_decompose\n",
    "fig,ax=plt.subplots(3,1,figsize=(20,20))\n",
    "\n",
    "result=seasonal_decompose(dm1['overall'],period=52,extrapolate_trend='freq')\n",
    "result.trend.plot(ax=ax[0])\n",
    "ax[0].set_title(\"Trend\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_title(\"Seasonal\")\n",
    "\n",
    "result.resid.plot(ax=ax[2])\n",
    "ax[2].set_title(\"Random\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 100)]\n",
    "test_df1 = dm1[slice(100, 189)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"------------------------------------TRAIN DATA----------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "train_df1['overall'].plot(ax=ax[0])\n",
    "train_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# TEST\n",
    "print(\"-------------------------------------TEST DATA------------------------------------------\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(20,5))\n",
    "col='overall'\n",
    "ax[0].set_title(col)\n",
    "ax[1].set_title(\"Weekly\"+col)\n",
    "test_df1['overall'].plot(ax=ax[0])\n",
    "test_df1['overall'].rolling(window=12).mean().plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e909040",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1['overall']\n",
    "dm1_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ee2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot shows stationarity\n",
    "dm1_overall.plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5baf3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dickey-fuller test for stationarity\n",
    "def checkStationarity(data):\n",
    "    pvalue = adfuller(data)[1]\n",
    "    if(pvalue>0.05):\n",
    "        msg = 'p-value={}. Data is not stationary. Make the data stationary before model building.'.format(pvalue)\n",
    "    else:\n",
    "        msg='p-value={}. Data is stationary. Proceed to model building'.format(pvalue)\n",
    "        \n",
    "    return(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cceb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data for stationarity\n",
    "checkStationarity(dm1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57757bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 12-level differencing, since the data is seasonal\n",
    "dm1_overall['diff12'] = dm1_overall.diff(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c09597",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test on differenced data\n",
    "res = adfuller(dm1_overall['diff12'].dropna())\n",
    "if res[1] < 0.05:\n",
    "    print('Data is stationary. Proceed to model building')\n",
    "else:\n",
    "    print('Data is not stationary. Make the data stationary before model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall = dm1_overall['diff12'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c15530",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = dm1[slice(0, 100)]\n",
    "test_df1 = dm1[slice(100, 177)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a58da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = auto_arima(dm1_overall, start_p = 0, max_p = 2, start_q = 0, max_q = 2, seasonal = False, trace = True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5402d",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680532e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ARIMA model\n",
    "# start with initial values for p and q based on auto_arima recommendation\n",
    "p = 1; d = 0; q = 1\n",
    "model_1 = ARIMA(dm1['overall'],order=(p,d,q)).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the model\n",
    "# predictions\n",
    "start = len(train_df1) \n",
    "end = len(train_df1) + len(test_df1) - 1\n",
    "\n",
    "print('start = {}, end = {}'.format(start,end))\n",
    "\n",
    "predictions1 = model_1.predict(start,end,typ='levels')\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42192bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate actual, predicted, and error values together\n",
    "# actual vs predicted values\n",
    "# print(\"test = {}, predicted = {}\".format(len(test), len(predictions) ))\n",
    "actual = []; pred = []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    actual.append(test_df1['overall'][i])\n",
    "    pred.append(predictions1[i])\n",
    "\n",
    "df_res = pd.DataFrame({'actual':actual, 'predicted':pred})\n",
    "df_res['error'] = df_res.actual - df_res.predicted\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce229f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39cae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Jenkins test to check model's goodness\n",
    "# LJung-Box test\n",
    "pvalue = sm.stats.acorr_ljungbox(model_1.resid,lags=[1],return_df=True)['lb_pvalue'].values\n",
    "if pvalue < 0.05:\n",
    "    print(\"Reject H0. Bad model\")\n",
    "else:\n",
    "    print(\"Accept H0. Good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24397841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error terms\n",
    "# MSE\n",
    "msg = 'ARIMA Model. Order=(' + str(p) + ',' + str(d) + ',' + str(q) + ')'\n",
    "mse = mean_squared_error(df_res.actual, df_res.predicted)\n",
    "print(msg + \"\\n\\tMSE = {}\\n\\tRMSE = {}\".format(mse,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.actual.plot(figsize=(10, 5),legend=True)\n",
    "df_res.predicted.plot(legend=True)\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49662583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "m1 = ARIMA(test_df1['overall'],order=(p,d,q)).fit()\n",
    "fcast = m1.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550113f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['overall'].plot(figsize=(10, 5),legend=True)\n",
    "fcast.plot(legend=True)\n",
    "plt.ylabel('sum of positive reviews')\n",
    "plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd344a",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a15470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal data, use the SARIMAX. start with initial values for p,d,q\n",
    "p=1; q=1; d=0\n",
    "m1 = sm.tsa.statespace.SARIMAX(dm1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10679b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c689c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = m1.predict(start=100,end=188,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'actual':dm1.overall[100:],'predicted':predictions})\n",
    "df_res['err'] = df_res.actual - df_res.predicted\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24094e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mean_squared_error(df_res.actual,df_res.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec442fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_res[['actual','predicted']].plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2dd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast into the future\n",
    "p=1; q=1; d=0\n",
    "m2 = sm.tsa.statespace.SARIMAX(test_df1['overall'],order=(p,d,q),seasonal_order=(p,d,q,52)).fit()\n",
    "fcast = m2.predict(start=len(test_df1), end=len(test_df1)+52, typ='levels').rename('Forecast')\n",
    "print(fcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1['overall'].plot(figsize=(10,5),legend=True, linewidth=1.0)\n",
    "plt.ylabel('sum of neutral reviews')\n",
    "fcast.plot(legend=True, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfb83b",
   "metadata": {},
   "source": [
    "# ratings\n",
    "\n",
    "## digital_music:\n",
    "\n",
    "##### importing data into dataframe format from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23693d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('ratings_Digital_Music.csv', header = None) # since no column names are mentioned in csv file\n",
    "\n",
    "# assigning column names to columns accoding to instruction given in link\n",
    "df3.columns = ['raterID', 'item', 'Ratings', 'timestamp'] \n",
    "\n",
    "# checking no. of rows and columns in the dataframe\n",
    "print(df3.shape)\n",
    "\n",
    "# top 3 records\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81dff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of non-numeric variables\n",
    "\n",
    "# Number of unique customers\n",
    "print('\\nNumber of unique customers : {}'.format(len(df3['raterID'].unique())))\n",
    "      \n",
    "# Number of unique products\n",
    "print('\\nNumber of unique products : {}'.format(len(df3['item'].unique())))\n",
    "      \n",
    "# Review number per unique customer\n",
    "print('\\nReview per customer: {}'.format((len(df3)/len(df3['raterID'].unique()))))      \n",
    "\n",
    "# Review number per unique product \n",
    "print('\\nReview per product: {}'.format((len(df3)/len(df3['item'].unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693f2e9",
   "metadata": {},
   "source": [
    "## musical_instruments: ratings\n",
    "\n",
    "##### importing data into dataframe format from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('ratings_Musical_Instruments.csv', header = None) # since no column names are mentioned in csv file\n",
    "\n",
    "# assigning column names to columns accoding to instruction given in link\n",
    "df4.columns = ['raterID', 'item', 'Ratings', 'timestamp'] \n",
    "\n",
    "# checking no. of rows and columns in the dataframe\n",
    "print(df4.shape)\n",
    "\n",
    "# top 3 records\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad6390",
   "metadata": {},
   "source": [
    "##### Distribution of Amazon Product Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of non-numeric variables\n",
    "\n",
    "# Number of unique customers\n",
    "print('\\nNumber of unique customers : {}'.format(len(df4['raterID'].unique())))\n",
    "      \n",
    "# Number of unique products\n",
    "print('\\nNumber of unique products : {}'.format(len(df4['item'].unique())))\n",
    "      \n",
    "# Review number per unique customer\n",
    "print('\\nReview per customer: {}'.format((len(df4)/len(df4['raterID'].unique()))))      \n",
    "\n",
    "# Review number per unique product \n",
    "print('\\nReview per product: {}'.format((len(df4)/len(df4['item'].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_plot(df):\n",
    "    ratings = df[\"Ratings\"].value_counts()\n",
    "    numbers = ratings.index\n",
    "    quantity = ratings.values\n",
    "\n",
    "    custom_colors = [\"green\", \"yellow\", 'red', \"blue\", \"black\"]\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    plt.pie(quantity, labels = numbers, colors = custom_colors)\n",
    "    central_circle = plt.Circle((0, 0), 0.5, color ='white')\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(central_circle)\n",
    "    plt.rc('font', size = 10)\n",
    "    plt.title(\"Distribution of Amazon Product Ratings\", fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9740b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_plot(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65150204",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_plot(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e709c2b",
   "metadata": {},
   "source": [
    "##### finding out item codes that have received the highest ratings and lowest ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a67954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_pos(df):\n",
    "    item_rate = df['item'].groupby(df['Ratings']).value_counts()\n",
    "    print(\"items with highest no of ratings\")\n",
    "    print((item_rate.sort_values(ascending = False)).head(10))\n",
    "    print(\"items with lowest no of ratings\")\n",
    "    print((item_rate.sort_values(ascending = False)).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pos(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pos(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9343c89",
   "metadata": {},
   "source": [
    "# FINDING COMMON USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_user = df3.raterID\n",
    "uni_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_user_ins = df4.raterID\n",
    "uni_user_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088602a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resData_1 = np.intersect1d(uni_user,uni_user_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c997a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = resData_1.tolist()\n",
    "print(f'List: {list1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand_list1=random.choices(list1, k=10)\n",
    "rand_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a89b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_rating = pd.concat([df3, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = product_rating.loc[product_rating['raterID'].isin(rand_list1)]\n",
    "rslt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88749c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df['item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92100914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 common users of digital music and musical instruments.\n",
    "rslt_df_g = rslt_df.groupby('raterID')['Ratings'].aggregate(['max','min'])\n",
    "print(rslt_df_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[(df3.raterID == 'A10LIAWGRJCXO3') | (df3.raterID == 'A157DYI1PMXDR1') | (df3.raterID == 'A2E5IK9TUH8UPD')\n",
    "    | (df3.raterID == 'A2SR0NOOXC6T6M') | (df3.raterID == 'A2V51XV0JBSTZG') | (df3.raterID == 'A2YI1QKFDR7Q1')\n",
    "   | (df3.raterID == 'A35L8QGI9PNDO4') | (df3.raterID == 'A5HNYT4I6HKWW') | (df3.raterID == 'A5K2APMMH02FJ')\n",
    "   | (df3.raterID == 'ATB5SOUSOIWJ8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1.reviewerID == 'A10LIAWGRJCXO3') | (df1.reviewerID == 'A157DYI1PMXDR1') | (df1.reviewerID == 'A2E5IK9TUH8UPD')\n",
    "    | (df1.reviewerID == 'A2SR0NOOXC6T6M') | (df1.reviewerID == 'A2V51XV0JBSTZG') | (df1.reviewerID == 'A2YI1QKFDR7Q1')\n",
    "   | (df1.reviewerID == 'A35L8QGI9PNDO4') | (df1.reviewerID == 'A5HNYT4I6HKWW') | (df1.reviewerID == 'A5K2APMMH02FJ')\n",
    "   | (df1.reviewerID == 'ATB5SOUSOIWJ8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[(df4.raterID == 'A10LIAWGRJCXO3') | (df4.raterID == 'A157DYI1PMXDR1') | (df4.raterID == 'A2E5IK9TUH8UPD')\n",
    "    | (df4.raterID == 'A2SR0NOOXC6T6M') | (df4.raterID == 'A2V51XV0JBSTZG') | (df4.raterID == 'A2YI1QKFDR7Q1')\n",
    "   | (df4.raterID == 'A35L8QGI9PNDO4') | (df4.raterID == 'A5HNYT4I6HKWW') | (df4.raterID == 'A5K2APMMH02FJ')\n",
    "   | (df4.raterID == 'ATB5SOUSOIWJ8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2.reviewerID == 'A10LIAWGRJCXO3') | (df2.reviewerID == 'A157DYI1PMXDR1') | (df2.reviewerID == 'A2E5IK9TUH8UPD')\n",
    "    | (df2.reviewerID == 'A2SR0NOOXC6T6M') | (df2.reviewerID == 'A2V51XV0JBSTZG') | (df2.reviewerID == 'A2YI1QKFDR7Q1')\n",
    "   | (df2.reviewerID == 'A35L8QGI9PNDO4') | (df2.reviewerID == 'A5HNYT4I6HKWW') | (df2.reviewerID == 'A5K2APMMH02FJ')\n",
    "   | (df2.reviewerID == 'ATB5SOUSOIWJ8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_user = df1.reviewerID\n",
    "uni_user\n",
    "\n",
    "uni_user_ins = df2.reviewerID\n",
    "uni_user_ins\n",
    "\n",
    "resData_1 = np.intersect1d(uni_user,uni_user_ins)\n",
    "\n",
    "list1 = resData_1.tolist()\n",
    "print(f'List: {list1}')\n",
    "\n",
    "import random\n",
    "rand_list1=random.choices(list1, k=10)\n",
    "rand_list1\n",
    "\n",
    "product_review = pd.concat([df1, df2])\n",
    "\n",
    "rslt_df = product_review.loc[product_review['reviewerID'].isin(rand_list1)]\n",
    "rslt_df\n",
    "\n",
    "rslt_df['asin'].value_counts()\n",
    "\n",
    "# 10 common users of digital music and musical instruments.\n",
    "rslt_df_g = rslt_df.groupby('reviewerID')['overall'].aggregate(['max','min'])\n",
    "print(rslt_df_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf459b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dm = df1[(df1.reviewerID == 'A13A81NN0NRD1S') | (df1.reviewerID == 'A18X6ZT4AEYVKB') | (df1.reviewerID == 'A1LQC225SE8UNI')\n",
    "    | (df1.reviewerID == 'A1MI9FDCNB3CMR') | (df1.reviewerID == 'A1T9SCT89JJ96') | (df1.reviewerID == 'A27L5L6I7OSV5B')\n",
    "   | (df1.reviewerID == 'A2C7BOQVFH1HLE') | (df1.reviewerID == 'A2CARFAX5FNQT9') | (df1.reviewerID == 'A2EW01G2LNJN06')\n",
    "   | (df1.reviewerID == 'A2KKZHISX9YKMI')]\n",
    "df_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe79ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df1 = df_dm.groupby('reviewerName')['overall'].aggregate(['max','min', 'mean'])\n",
    "print(rslt_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dm['reviewerName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud(df_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(analyzer='word')\n",
    "def review_wordcloud(data,title):\n",
    "    wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(5 ,5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
    "    plt.show()\n",
    "\n",
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable = ['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "df_dm['review'] = df_dm['review'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))\n",
    "\n",
    "df_grouped1 = df_dm[['asin','review']].groupby(by='asin').agg(lambda x:' '.join(x))\n",
    "df_grouped1\n",
    "\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "data = cv.fit_transform(df_grouped1['review'])\n",
    "df_dm = pd.DataFrame(data.toarray(), columns = cv.get_feature_names())\n",
    "df_dm.index = df_grouped1.index\n",
    "df_dm = df_dm.transpose()\n",
    "df_dm.head(3)    \n",
    "\n",
    "# Plotting word cloud for each product\n",
    "for index,product in enumerate(df_dm.columns):\n",
    "    review_wordcloud(df_dm[product].sort_values(ascending=False),product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi = df2[(df2.reviewerID == 'A13A81NN0NRD1S') | (df2.reviewerID == 'A18X6ZT4AEYVKB') | (df2.reviewerID == 'A1LQC225SE8UNI')\n",
    "    | (df2.reviewerID == 'A1MI9FDCNB3CMR') | (df2.reviewerID == 'A1T9SCT89JJ96') | (df2.reviewerID == 'A27L5L6I7OSV5B')\n",
    "   | (df2.reviewerID == 'A2C7BOQVFH1HLE') | (df2.reviewerID == 'A2CARFAX5FNQT9') | (df2.reviewerID == 'A2EW01G2LNJN06')\n",
    "   | (df2.reviewerID == 'A2KKZHISX9YKMI')]\n",
    "df_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46271732",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df2 = df_mi.groupby('reviewerName')['overall'].aggregate(['max','min', 'mean'])\n",
    "print(rslt_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi['reviewerName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common products\n",
    "cloud(df_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497a85a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer(analyzer='word')\n",
    "def review_wordcloud(data,title):\n",
    "    wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(5 ,5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
    "    plt.show()\n",
    "\n",
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable = ['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "df_mi['review'] = df_mi['review'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))\n",
    "\n",
    "df_grouped1 = df_mi[['asin','review']].groupby(by='asin').agg(lambda x:' '.join(x))\n",
    "df_grouped1\n",
    "\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "data = cv.fit_transform(df_grouped1['review'])\n",
    "df_mi = pd.DataFrame(data.toarray(), columns = cv.get_feature_names())\n",
    "df_mi.index = df_grouped1.index\n",
    "df_mi = df_mi.transpose()\n",
    "df_mi.head(3)    \n",
    "\n",
    "# Plotting word cloud for each product\n",
    "for index,product in enumerate(df_mi.columns):\n",
    "    review_wordcloud(df_mi[product].sort_values(ascending=False),product)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
